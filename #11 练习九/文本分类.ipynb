{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集$D=\\{(\\mathbf{x}^{(1)},y^{(1)}),(\\mathbf{x}^{(2)},y^{(2)}),\\cdots,(\\mathbf{x}^{(N)},y^{(N)})\\}$，其中$\\mathbf{x}^{(i)}=(x^{(i)}_1,x^{(i)}_1,\\cdots,x^{(i)}_M)$，$𝑦^{(i)}∈\\{c_1,c_2,\\cdots,c_K\\}$属于$K$类中的一类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据贝叶斯定理，给定样本特征$x$，样本属于类别$y$的概率是\n",
    "$$P(y | x)= \\frac{P(xy)}{P(x)} = \\frac{P(x | y) P(y)}{P(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设特征条件独立，则样本$x$为类别$c_k$的概率可以表示为\n",
    "$$P\\left(y=c_{k} | x\\right)=\\frac{\\prod_{j=1}^{M} P\\left(x_{j} | y=c_{k}\\right) P\\left(y=c_{k}\\right)}{P(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**学习过程** \n",
    "计算上式中的概率值\n",
    "$$P(y=c_k) = \\frac{\\sum_{i=1}^N I(y^{(i)}=c_k)}{N}$$\n",
    "其中$I(x)$为指示函数，若括号内成立，则为1，否则为0。\n",
    "$$P(x_j=a_{jl}|y=c_k )= \\frac{\\sum_{i=1}^N I(x_j^{(i)}=a_{jl},y^{(i)}=c_k)}{\\sum_{i=1}^N I(y^{(i)}=c_k))},$$\n",
    "$$j=1,2,\\cdots, M, \\quad k=1,2,\\cdots,K,\\quad l=1,2,\\cdots, L_j$$\n",
    "其中$L_j$为第$j$个特征取值的个数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分类过程** 通过学到的概率，给定未分类新实例$X$，就可以通过上述概率进行计算，得到该实例属于各类的后验概率$P(y=c_k|X)$ ，计算如下：\n",
    " - 计算该实例属于$y=c_k$类的概率\n",
    " $$P\\left(y=c_{k} | X\\right)=\\frac{\\prod_{j=1}^{M} P\\left(X_{j} | y=c_{k}\\right) P\\left(y=c_{k}\\right)}{P(X)}$$\n",
    " - 确定该实例所属的类别 $y$\n",
    " $$𝑦 = \\arg\\max\\limits_{𝑐_𝑘} \\prod_{j=1}^{M} P\\left(X_{j} | y=c_{k}\\right) P\\left(y=c_{k}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过男生的四个特点分别是不帅，性格不好，身高矮，不上进，判断一下女生是嫁还是不嫁？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 长相 | 性格 | 身高 | 是否上进 | 嫁否 | \n",
    "|:----:|:----:|:----:|:----:|:----:|\n",
    "| 帅 | 不好 | 矮 | 不上进 | 不嫁 | \n",
    "| 不帅 | 好 | 矮 | 上进 | 不嫁 | \n",
    "| 帅 | 好 | 矮 | 上进 | 嫁 | \n",
    "| 不帅 | 好 | 高 | 上进 | 嫁 | \n",
    "| 帅 | 不好 | 矮 | 上进 | 不嫁 | \n",
    "| 不帅 | 不好 | 矮 | 不上进 | 不嫁 | \n",
    "| 帅 | 好 | 高 | 不上进 | 嫁 | \n",
    "| 不帅 | 好 | 高 | 上进 | 嫁 | \n",
    "| 帅 | 好 | 高 | 上进 | 嫁 | \n",
    "| 不帅 | 不好 | 高 | 上进 | 嫁 | \n",
    "| 帅 | 好 | 矮 | 不上进 | 不嫁 | \n",
    "| 帅 | 好 | 矮 | 不上进 | 不嫁 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先计算嫁的概率\n",
    "\\begin{align*}\n",
    "&P(\\text{嫁}|\\text{不帅、性格不好、身高矮、不上进}) \\\\\n",
    "&=\\frac{P(\\text{不帅、性格不好、身高矮、不上进}|\\text{嫁})P(\\text{嫁})}{P(\\text{不帅、性格不好、身高矮、不上进})} \\\\\n",
    "&=\\frac{P(\\text{不帅}|\\text{嫁})P(\\text{性格不好}|\\text{嫁})P(\\text{身高矮}|\\text{嫁})P(\\text{不上进}|\\text{嫁})P(\\text{嫁})}{ P(\\text{不帅、性格不好、身高矮、不上进})} \\\\ \n",
    "&=\\frac{\\frac{3}{6}\\frac{1}{6}\\frac{1}{6}\\frac{1}{6}\\frac{6}{12}}{P(\\text{不帅、性格不好、身高矮、不上进})} \\\\\n",
    "&=\\frac{\\frac{1}{864}}{P(\\text{不帅、性格不好、身高矮、不上进})}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再计算不嫁的概率\n",
    "\\begin{align*}\n",
    "&P(\\text{不嫁}|\\text{不帅、性格不好、身高矮、不上进}) \\\\\n",
    "&=\\frac{P(\\text{不帅、性格不好、身高矮、不上进}|\\text{不嫁})P(\\text{不嫁})}{P(\\text{不帅、性格不好、身高矮、不上进})} \\\\\n",
    "&=\\frac{P(\\text{不帅}|\\text{不嫁})P(\\text{性格不好}|\\text{不嫁})P(\\text{身高矮}|\\text{不嫁})P(\\text{不上进}|\\text{不嫁})P(\\text{不嫁})}{ P(\\text{不帅、性格不好、身高矮、不上进})} \\\\ \n",
    "&=\\frac{\\frac{2}{6}\\frac{3}{6}\\frac{6}{6}\\frac{4}{6}\\frac{6}{12}}{P(\\text{不帅、性格不好、身高矮、不上进})} \\\\\n",
    "&=\\frac{\\frac{1}{18}}{P(\\text{不帅、性格不好、身高矮、不上进})}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较两个概率值\n",
    "$$P(\\text{嫁}|(\\text{不帅、性格不好、身高矮、不上进})<P(\\text{不嫁}|(\\text{不帅、性格不好、身高矮、不上进})$$\n",
    "得出结论：不嫁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 0. 1.]]\n",
      "[0]\n",
      "[[0.92920354 0.07079646]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "X = [[\"帅\",\"不好\",\"矮\",\"不上进\"],\n",
    "        [\"不帅\",\"好\",\"矮\",\"上进\"],\n",
    "        [\"帅\",\"好\",\"矮\",\"上进\"],\n",
    "        [\"不帅\",\"好\",\"高\",\"上进\"],\n",
    "        [\"帅\",\"不好\",\"矮\",\"上进\"],\n",
    "        [\"不帅\",\"不好\",\"矮\",\"不上进\"],\n",
    "        [\"帅\",\"好\",\"高\",\"不上进\"],\n",
    "        [\"不帅\",\"好\",\"高\",\"上进\"],\n",
    "        [\"帅\",\"好\",\"高\",\"上进\"],\n",
    "        [\"不帅\",\"不好\",\"高\",\"上进\"],\n",
    "        [\"帅\",\"好\",\"矮\",\"不上进\"],\n",
    "        [\"帅\",\"好\",\"矮\",\"不上进\"]]\n",
    "y = [0,0,1,1,0,0,1,1,1,1,0,0] #类别标签，1 嫁, 0 不嫁\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(X)\n",
    "X_train = enc.transform(X) \n",
    "print(X_train)\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X_train, y)\n",
    "\n",
    "testEntry = np.array([\"不帅\",\"不好\",\"矮\",\"不上进\"]).reshape(1, -1)\n",
    "y_pred = clf.predict(enc.transform(testEntry))\n",
    "print(y_pred)\n",
    "# 预测每个类别的概率值\n",
    "y_pred_proba = clf.predict_proba(enc.transform(testEntry))\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现朴素贝叶斯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['好', '上进', '不上进', '高', '不帅', '矮', '不好', '帅']\n",
      "[0.5        0.33333333 0.66666667 0.         0.33333333 1.\n",
      " 0.5        0.66666667] [0.83333333 0.83333333 0.16666667 0.83333333 0.5        0.16666667\n",
      " 0.16666667 0.5       ] 0.5\n",
      "0.0011574074074074073 0.05555555555555555\n",
      "['不帅', '不好', '矮', '不上进'] classified as:  0\n",
      "0.14467592592592596 0.05555555555555555\n",
      "['帅', '好', '高', '上进'] classified as:  1\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def createVocabList(dataSet):\n",
    "    \"\"\"\n",
    "    由数据集产生词典\n",
    "    \"\"\"\n",
    "    vocabSet = set([])  #create empty set\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document) #union of the two sets\n",
    "    return list(vocabSet)\n",
    "\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    \"\"\"\n",
    "    将句子转成向量，向量的长度为词典中词的个数\n",
    "    \"\"\"\n",
    "    returnVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else: \n",
    "            print (\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec\n",
    "\n",
    "def trainNB0(trainMatrix,trainCategory):\n",
    "    \"\"\"\n",
    "    训练模型\n",
    "    \"\"\"\n",
    "    numTrainDocs = len(trainMatrix) # 数据量\n",
    "    numWords = len(trainMatrix[0]) # 向量长度\n",
    "    pPositive = sum(trainCategory)/float(numTrainDocs) # 正例出现的概率\n",
    "    p0Num = np.zeros(numWords); \n",
    "    p1Num = np.zeros(numWords) \n",
    " \n",
    "    p0Denom = 0.0\n",
    "    p1Denom = 0.0                        \n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            # 注意分子是一个向量\n",
    "            p1Num += trainMatrix[i]\n",
    "            p1Denom += 1\n",
    "            \n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += 1\n",
    "            \n",
    "    # 分别存的是在两个类别下，每个特征取值的概率\n",
    "    p1Vect = p1Num/p1Denom          \n",
    "    p0Vect = p0Num/p0Denom\n",
    "    return p0Vect,p1Vect,pPositive\n",
    "\n",
    "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    \"\"\"\n",
    "    使用训练结果进行分类\n",
    "    \"\"\"\n",
    "    p1 = vec2Classify * p1Vec \n",
    "    p0 = vec2Classify * p0Vec \n",
    "    p1 = reduce(lambda x,y:x*y,[item for item in p1 if item != 0 ])*pClass1\n",
    "    p0 = reduce(lambda x,y:x*y,[item for item in p0 if item != 0 ])*(1 - pClass1)\n",
    "    print(p1,p0)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "myVocabList = createVocabList(X)\n",
    "print(myVocabList)\n",
    "\n",
    "trainMat=[]\n",
    "for item in X:\n",
    "    trainMat.append(setOfWords2Vec(myVocabList, item))\n",
    "p0V,p1V,pAb = trainNB0(np.array(trainMat),np.array(y))\n",
    "print(p0V,p1V,pAb)\n",
    "\n",
    "testEntry = [\"不帅\",\"不好\",\"矮\",\"不上进\"]\n",
    "thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))\n",
    "print (testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb))\n",
    "\n",
    "testEntry = [\"帅\",\"好\",\"高\",\"上进\"]\n",
    "thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))\n",
    "print (testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ['my dog has flea problems help please my dog has flea problems help please',\n",
    "             'maybe not take him to dog park stupid',\n",
    "             'my dalmation is so cute I love him',\n",
    "             'stop posting stupid worthless garbage',\n",
    "             'mr licks ate my steak how to stop him',\n",
    "             'quit buying worthless dog food stupid']\n",
    "y_train = [0,1,0,1,0,1]    #类别标签，1 is abusive, 0 not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17)\t2\n",
      "  (0, 4)\t2\n",
      "  (0, 8)\t2\n",
      "  (0, 5)\t2\n",
      "  (0, 22)\t2\n",
      "  (0, 9)\t2\n",
      "  (0, 20)\t2\n",
      "  (1, 4)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 18)\t1\n",
      "  (1, 28)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 27)\t1\n",
      "  (2, 17)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 24)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 14)\t1\n",
      "  (3, 27)\t1\n",
      "  (3, 26)\t1\n",
      "  (3, 21)\t1\n",
      "  (3, 30)\t1\n",
      "  (3, 7)\t1\n",
      "  (4, 17)\t1\n",
      "  (4, 10)\t1\n",
      "  (4, 29)\t1\n",
      "  (4, 26)\t1\n",
      "  (4, 16)\t1\n",
      "  (4, 13)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 25)\t1\n",
      "  (4, 11)\t1\n",
      "  (5, 4)\t1\n",
      "  (5, 27)\t1\n",
      "  (5, 30)\t1\n",
      "  (5, 23)\t1\n",
      "  (5, 1)\t1\n",
      "  (5, 6)\t1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.feature_extraction.text里导入文本特征向量化模块\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.naive_bayes import MultinomialNB     \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#文本特征向量化，词频作为特征\n",
    "vec = CountVectorizer()\n",
    "# X 是稀疏矩阵，类型为scipy.sparse.csr.csr_matrix\n",
    "X = vec.fit_transform(X_train)\n",
    "print(X)\n",
    "\n",
    "#使用朴素贝叶斯进行训练\n",
    "mnb = MultinomialNB()   # 使用默认配置初始化朴素贝叶斯\n",
    "mnb.fit(X,y_train)    # 利用训练数据对模型参数进行估计\n",
    "\n",
    "testEntry = ['love my dalmation']\n",
    "pred = mnb.predict(vec.transform(testEntry))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 20)\t0.40966431929307107\n",
      "  (0, 9)\t0.40966431929307107\n",
      "  (0, 22)\t0.40966431929307107\n",
      "  (0, 5)\t0.40966431929307107\n",
      "  (0, 8)\t0.40966431929307107\n",
      "  (0, 4)\t0.2836156972830696\n",
      "  (0, 17)\t0.2836156972830696\n",
      "  (1, 27)\t0.28007245489665356\n",
      "  (1, 19)\t0.4045463374809687\n",
      "  (1, 29)\t0.33173378384997615\n",
      "  (1, 10)\t0.28007245489665356\n",
      "  (1, 28)\t0.4045463374809687\n",
      "  (1, 18)\t0.4045463374809687\n",
      "  (1, 15)\t0.4045463374809687\n",
      "  (1, 4)\t0.28007245489665356\n",
      "  (2, 14)\t0.40966431929307107\n",
      "  (2, 2)\t0.40966431929307107\n",
      "  (2, 24)\t0.40966431929307107\n",
      "  (2, 12)\t0.40966431929307107\n",
      "  (2, 3)\t0.40966431929307107\n",
      "  (2, 10)\t0.2836156972830696\n",
      "  (2, 17)\t0.2836156972830696\n",
      "  (3, 7)\t0.5113672547493431\n",
      "  (3, 30)\t0.41932846410444796\n",
      "  (3, 21)\t0.5113672547493431\n",
      "  (3, 26)\t0.41932846410444796\n",
      "  (3, 27)\t0.3540259028995622\n",
      "  (4, 11)\t0.37002943283285533\n",
      "  (4, 25)\t0.37002943283285533\n",
      "  (4, 0)\t0.37002943283285533\n",
      "  (4, 13)\t0.37002943283285533\n",
      "  (4, 16)\t0.37002943283285533\n",
      "  (4, 26)\t0.3034294282673573\n",
      "  (4, 29)\t0.3034294282673573\n",
      "  (4, 10)\t0.25617597302407796\n",
      "  (4, 17)\t0.25617597302407796\n",
      "  (5, 6)\t0.4646884077430666\n",
      "  (5, 1)\t0.4646884077430666\n",
      "  (5, 23)\t0.4646884077430666\n",
      "  (5, 30)\t0.38105114180913807\n",
      "  (5, 27)\t0.32170955725125144\n",
      "  (5, 4)\t0.32170955725125144\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.feature_extraction.text里导入文本特征向量化模块\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#文本特征向量化，tfidf作为特征\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(X_train)\n",
    "print(X)\n",
    "\n",
    "#使用朴素贝叶斯进行训练\n",
    "mnb = MultinomialNB() \n",
    "mnb.fit(X,y_train)   \n",
    "\n",
    "tfidf.transform(testEntry)\n",
    "testEntry = ['love my dalmation']\n",
    "pred = mnb.predict(tfidf.transform(testEntry))\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新闻语料分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "The Accuracy of Naive Bayes Classifier is: 0.8463497453310697\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.84      0.67      0.75       201\n",
      "           comp.graphics       0.85      0.74      0.79       250\n",
      " comp.os.ms-windows.misc       0.82      0.85      0.83       248\n",
      "comp.sys.ibm.pc.hardware       0.76      0.88      0.82       240\n",
      "   comp.sys.mac.hardware       0.94      0.84      0.89       242\n",
      "          comp.windows.x       0.96      0.84      0.89       263\n",
      "            misc.forsale       0.93      0.69      0.79       257\n",
      "               rec.autos       0.84      0.92      0.88       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.96      0.91      0.94       251\n",
      "        rec.sport.hockey       0.88      0.99      0.93       233\n",
      "               sci.crypt       0.73      0.98      0.83       238\n",
      "         sci.electronics       0.91      0.83      0.87       249\n",
      "                 sci.med       0.97      0.92      0.95       245\n",
      "               sci.space       0.89      0.96      0.93       221\n",
      "  soc.religion.christian       0.51      0.97      0.67       232\n",
      "      talk.politics.guns       0.83      0.96      0.89       251\n",
      "   talk.politics.mideast       0.92      0.97      0.95       231\n",
      "      talk.politics.misc       0.98      0.62      0.76       188\n",
      "      talk.religion.misc       0.93      0.16      0.28       158\n",
      "\n",
      "                accuracy                           0.85      4712\n",
      "               macro avg       0.87      0.83      0.83      4712\n",
      "            weighted avg       0.87      0.85      0.84      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups  # 从sklearn.datasets里导入新闻数据抓取器 fetch_20newsgroups\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # 从sklearn.feature_extraction.text里导入文本特征向量化模块\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "from sklearn.naive_bayes import MultinomialNB     # 从sklean.naive_bayes里导入朴素贝叶斯模型\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1.数据获取\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "print(len(news.data))  # 输出数据的条数：18846\n",
    "\n",
    "#2.数据预处理：训练集和测试集分割，文本特征向量化\n",
    "X_train,X_test,y_train,y_test = train_test_split(news.data,news.target,test_size=0.25,random_state=33) # 随机采样25%的数据样本作为测试集\n",
    "#print X_train[0]  #查看训练样本\n",
    "#print y_train[0:100]  #查看标签\n",
    "\n",
    "#词频文本特征向量化\n",
    "# vec = CountVectorizer()\n",
    "# X_train = vec.fit_transform(X_train)\n",
    "# X_test = vec.transform(X_test)\n",
    "\n",
    "# tfidf文本特征向量化\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "\n",
    "#3.使用朴素贝叶斯进行训练\n",
    "mnb = MultinomialNB()   # 使用默认配置初始化朴素贝叶斯\n",
    "mnb.fit(X_train,y_train)    # 利用训练数据对模型参数进行训练\n",
    "y_predict = mnb.predict(X_test)     \n",
    "\n",
    "#4.获取结果报告\n",
    "print('The Accuracy of Naive Bayes Classifier is:', mnb.score(X_test,y_test))\n",
    "print(classification_report(y_test, y_predict, target_names = news.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果数据下载很慢或是下载失败，可以手动下载。然后\n",
    "\n",
    "将文件 C:/Users/lei/.conda/envs/shumo/Lib/site-packages/sklearn/datasets/_twenty_newsgroups.py 73行\n",
    "\n",
    "archive_path = _fetch_remote(ARCHIVE, dirname=target_dir)\n",
    "\n",
    "改为\n",
    "archive_path = 下载的文件存放位置<br>\n",
    "例如：archive_path = \"C:/Users/lei/.conda/envs/shumo/Lib/site-packages/sklearn/datasets/data/20newsbydate.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用卡方检验进行特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "选择特征前数据维度： 150725\n",
      "选择特征后数据维度： 10000\n",
      "The Accuracy of Naive Bayes Classifier is: 0.8529286926994907\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.74      0.79       201\n",
      "           comp.graphics       0.81      0.75      0.78       250\n",
      " comp.os.ms-windows.misc       0.78      0.85      0.81       248\n",
      "comp.sys.ibm.pc.hardware       0.73      0.84      0.78       240\n",
      "   comp.sys.mac.hardware       0.91      0.85      0.88       242\n",
      "          comp.windows.x       0.93      0.85      0.88       263\n",
      "            misc.forsale       0.92      0.73      0.81       257\n",
      "               rec.autos       0.87      0.92      0.89       238\n",
      "         rec.motorcycles       0.97      0.93      0.95       276\n",
      "      rec.sport.baseball       0.95      0.93      0.94       251\n",
      "        rec.sport.hockey       0.88      0.98      0.93       233\n",
      "               sci.crypt       0.82      0.97      0.89       238\n",
      "         sci.electronics       0.89      0.80      0.84       249\n",
      "                 sci.med       0.95      0.90      0.92       245\n",
      "               sci.space       0.86      0.96      0.91       221\n",
      "  soc.religion.christian       0.59      0.95      0.73       232\n",
      "      talk.politics.guns       0.83      0.95      0.89       251\n",
      "   talk.politics.mideast       0.92      0.97      0.94       231\n",
      "      talk.politics.misc       0.96      0.70      0.81       188\n",
      "      talk.religion.misc       0.96      0.28      0.43       158\n",
      "\n",
      "                accuracy                           0.85      4712\n",
      "               macro avg       0.87      0.84      0.84      4712\n",
      "            weighted avg       0.87      0.85      0.85      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#1.数据获取\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "print(len(news.data))  # 输出数据的条数：18846\n",
    "\n",
    "#2.数据预处理：训练集和测试集分割，文本特征向量化\n",
    "X_train,X_test,y_train,y_test = train_test_split(news.data,news.target,test_size=0.25,random_state=33) # 随机采样25%的数据样本作为测试集\n",
    "#print X_train[0]  #查看训练样本\n",
    "#print y_train[0:100]  #查看标签\n",
    "\n",
    "#词频文本特征向量化\n",
    "# vec = CountVectorizer()\n",
    "# X_train = vec.fit_transform(X_train)\n",
    "# X_test = vec.transform(X_test)\n",
    "\n",
    "# tfidf文本特征向量化\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "print(\"选择特征前数据维度：\",X_train.shape[1])\n",
    "\n",
    "#3. 特征选择\n",
    "select_model = SelectKBest(chi2, k=10000)#选择k个最佳特征\n",
    "X_train = select_model.fit_transform(X_train,y_train)\n",
    "X_test = select_model.transform(X_test)\n",
    "print(\"选择特征后数据维度：\",X_train.shape[1])\n",
    "\n",
    "\n",
    "#4.使用朴素贝叶斯进行训练\n",
    "mnb = MultinomialNB()   # 使用默认配置初始化朴素贝叶斯\n",
    "mnb.fit(X_train,y_train)    # 利用训练数据对模型参数进行训练\n",
    "y_predict = mnb.predict(X_test)\n",
    "\n",
    "#5.获取结果报告\n",
    "print('The Accuracy of Naive Bayes Classifier is:', mnb.score(X_test,y_test))\n",
    "print(classification_report(y_test, y_predict, target_names = news.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**逻辑回归模型** 二项逻辑回归模型是如下的条件概率分布：\n",
    "$$P(Y=1|X)=\\frac{1}{1 + \\textrm{exp}(-(w \\cdot X + b))}$$\n",
    "$$P(Y=0|X)=\\frac{\\textrm{exp}(-(w\\cdot x +b))}{1 + \\textrm{exp}(-(w \\cdot X + b))}$$\n",
    "其中，$X\\in R^n$是输入，$Y \\in \\{0,1\\}$是输出，$w\\in R^n$和$b\\in R$是参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "z = np.arange(-7, 7, 0.1) # 从-7 到 7 画图\n",
    "phi_z = sigmoid(z)\n",
    "plt.plot(z, phi_z)\n",
    "plt.axvline(0.0, color='k')\n",
    "plt.axhline(0.5, color='k')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\phi(z)$')\n",
    "# y axis ticks and gridline\n",
    "plt.yticks([0.0, 0.5, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二分问题，由贝叶斯定理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "P(Y=1 | X) &=\\frac{P(X | Y=1) P(Y=1)}{P(X)} \\\\\n",
    "&=\\frac{P(X | Y=1) P(Y=1)}{P(x | Y=1) P(Y=1)+ P(x | Y=0) P(Y=0)} \\\\\n",
    "&=\\frac{1}{1+\\exp (-\\alpha)}=\\sigma(\\alpha) \\\\\n",
    "\\end{align*}\n",
    "其中 \n",
    "$$\\alpha=\\ln \\frac{P(X | Y=1) P(Y=1)}{P(X | Y=0) P(Y=0)}$$\n",
    "\n",
    "生成模型例如朴素贝叶斯模型，估计条件概率$P(X|Y)$从而决定$\\alpha$的值来分类。逻辑回归没有对条件概率进行估计，转而通过$w \\cdot X + b$近似估计$\\alpha$。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若将二分类推广到的多分类问题$K>2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "P\\left(Y_{i} | X\\right) &=\\frac{P\\left(X | Y_{i}\\right) P\\left(Y_{i}\\right)}{\\sum_{j=1}^{K} P\\left(X | Y_{j}\\right) P\\left(Y_{j}\\right)} \\\\\n",
    "&=\\frac{\\exp \\left(a_{i}\\right)}{\\sum_{j=1}^{K} \\exp \\left(a_{j}\\right)} \\\\\n",
    "\\end{align*}\n",
    "其中 $$a_{j} =\\ln \\left(P\\left(X | Y_{j}\\right) P\\left(Y_{j}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和二分问题类似，用$w \\cdot X + b$近似估计$a_j$,这就是Softmax。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对数线性模型（log-linear model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数线性模型广泛地应用自然语言处理中，它最大的优点是可以在模型中使用丰富的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对数线性模型** 一个对数线性模型由以下部分构成：\n",
    "- 输入集合 $\\mathcal{X}$，\n",
    "- 标签集合 $\\mathcal{Y}$，$\\mathcal{Y}$ 通常是一个有限集，\n",
    "- 函数 $f: \\mathcal{X} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}^{d}$ 将 $(x, y)$ 映射为特征向量 $f(x, y)$，\n",
    "- 参数向量 $v \\in \\mathbb{R}^{d}$，$d$ 为特征的个数。\n",
    "\n",
    "对任意$x \\in \\mathcal{X},y \\in \\mathcal{Y}$, 模型定义一个条件概率\n",
    "$$\n",
    "p(y | x ; v)=\\frac{\\exp (v \\cdot f(x, y))}{\\sum_{y^{\\prime} \\in \\mathcal{Y}} \\exp \\left(v \\cdot f\\left(x, y^{\\prime}\\right)\\right)}\n",
    "$$\n",
    "这里$\\exp (x)=e^{x},$ $v \\cdot f(x, y)=\\sum_{k=1}^{d} v_{k} f_{k}(x, y)$ 是 $v$ 和 $f(x, y)$的内积。 $p(y | x ; v)$ 理解为 $y$ 关于 $x$ 在参数$v$下的条件概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为什么叫称作对数线性模型？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\log p(y | x ; v) &=v \\cdot f(x, y)-\\log \\sum_{y^{\\prime} \\in \\mathcal{Y}} \\exp \\left(v \\cdot f\\left(x, y^{\\prime}\\right)\\right) \\\\\n",
    "&=v \\cdot f(x, y)-g(x)\n",
    "\\end{align*}\n",
    "\n",
    "其中\n",
    "$$g(x)=\\log \\sum_{y^{\\prime} \\in \\mathcal{Y}} \\exp \\left(v \\cdot f\\left(x, y^{\\prime}\\right)\\right)$$\n",
    "第一项$v \\cdot f(x, y)$关于特征$f(x,y)$是线性的。第二项$g(x)$只依赖$x$，不依赖$y$。因此固定$x$，$\\log p(y|x;v)$是特征$f(x,y)$的线性函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑数据集 $\\{x^{(i)}, y^{(i)}\\}$,$i \\in$ $\\{1 \\ldots n\\}$, 其中 $x^{(i)} \\in \\mathcal{X}$, $y^{(i)} \\in \\mathcal{Y}$.\n",
    "给定参数 $v,$ 对每个样本$i$,可以计算对数条件概率\n",
    "\n",
    "$$ \\log p\\left(y^{(i)} | x^{(i)} ; v\\right)$$\n",
    "\n",
    "直观上理解，这个值越高模型对样本的拟合越好. 整个数据集的对数似然函数为\n",
    "$$ L(v)=\\sum_{i=1}^{n} \\log p\\left(y^{(i)} | x^{(i)} ; v\\right) $$\n",
    "\n",
    "使用最大似然估计寻找最优参数\n",
    "$$v_{M L}=\\arg \\max _{v \\in \\mathbb{R}^{d}} L(v)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
