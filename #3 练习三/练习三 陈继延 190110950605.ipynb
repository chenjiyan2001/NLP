{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库并配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:36:39.128490Z",
     "start_time": "2021-04-04T10:36:37.158889Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import logging\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import os\n",
    "from math import log\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:36:39.143765Z",
     "start_time": "2021-04-04T10:36:39.129461Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "word_dict_path = \"./jieba_dict.txt\" # jieba的字典\n",
    "SogouW = \"./SogouW/Freq/SogouLabDic.dic\" # Sogou字典\n",
    "sighan05 = \"./第二届国际中文分词评测/icwb2-data/\" # 语料库\n",
    "msr_test = os.path.join(sighan05, 'testing', 'msr_test.utf8') # 测试集\n",
    "msr_output = os.path.join(sighan05, 'testing', 'msr_output.txt') # 保存输出结果的空文件\n",
    "msr_gold = os.path.join(sighan05, 'gold', 'msr_test_gold.utf8') # 测试集的正确结果\n",
    "OUTFRMAE = \"P:\\t%.2f\\nR:\\t%.2f\\nF1:\\t%.2f\\nOOV-R:\\t%.2f\\nIV-R:\\t%.2f\" # 准确性结果的输出格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:36:39.158699Z",
     "start_time": "2021-04-04T10:36:39.144734Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)  # 调试模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T10:38:55.512573Z",
     "start_time": "2021-03-30T10:38:55.132591Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dictionary(dict_file):\n",
    "    fr = open(dict_file,encoding=\"utf-8\")\n",
    "    word_dict = {item.strip().split(\" \")[0]:item.strip().split(\" \")[1] for item in fr}\n",
    "    return word_dict\n",
    "\n",
    "word_dict = load_dictionary(word_dict_path) # 读取词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业\n",
    "对一元语法分词器的性能在MSR语料库上进行评测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于课上代码整理为类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:36:43.708066Z",
     "start_time": "2021-04-04T10:36:43.689143Z"
    }
   },
   "outputs": [],
   "source": [
    "class wordCut():\n",
    "    def __init__(self):\n",
    "        self.f = open(\"jieba_dict.txt\",encoding=\"utf-8\")\n",
    "        self.FREQ, self.total = self.gen_pfdict(self.f)\n",
    "        self.re_eng = re.compile('[a-zA-Z0-9]', re.U)   \n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.INFO) \n",
    "\n",
    "    def gen_pfdict(self,f):\n",
    "        lfreq = {}\n",
    "        ltotal = 0\n",
    "        for lineno, line in enumerate(f, 1):\n",
    "            try:\n",
    "                line = line.strip()\n",
    "                word, freq = line.split(' ')[:2]\n",
    "                freq = int(freq)\n",
    "                lfreq[word] = freq\n",
    "                ltotal += freq\n",
    "                for ch in range(len(word)):\n",
    "                    wfrag = word[:ch + 1]\n",
    "                    if wfrag not in lfreq:\n",
    "                        lfreq[wfrag] = 0 # 不在词典里的前缀，词频设为零，前提是词典已经进行排序\n",
    "            except ValueError:\n",
    "                raise ValueError(\n",
    "                    'invalid dictionary entry in %s at Line %s: %s' % (f.name, lineno, line))\n",
    "        f.close()\n",
    "        return lfreq, ltotal\n",
    "    \n",
    "    def get_DAG(self,sentence):\n",
    "        DAG = {}\n",
    "        N = len(sentence)\n",
    "        for k in range(N):\n",
    "            logging.debug(\"k = %s\"%k)\n",
    "            tmplist = []\n",
    "            i = k\n",
    "            frag = sentence[k]\n",
    "            logging.debug(\"for 循环 frag: %s\"%frag)\n",
    "            while i < N and frag in self.FREQ:\n",
    "                logging.debug(\"\\t 进入while...\")\n",
    "                logging.debug(\"\\t i = %s\"%i)\n",
    "                logging.debug(\"\\t FREQ[%s]: %s\"%(frag,self.FREQ[frag]))\n",
    "                if self.FREQ[frag]:\n",
    "                    tmplist.append(i)\n",
    "                i += 1\n",
    "                frag = sentence[k:i + 1]\n",
    "                logging.debug(\"\\t while 循环 frag: %s\"%frag)\n",
    "                logging.debug(\"\\t tmplist: %s\"%tmplist)\n",
    "            if not tmplist:\n",
    "                tmplist.append(k)\n",
    "                logging.debug(\"\\t if 语句 tmplist: %s\"%tmplist)\n",
    "            DAG[k] = tmplist\n",
    "        return DAG\n",
    "\n",
    "    def calc(self,sentence, DAG, route):\n",
    "        N = len(sentence)\n",
    "        route[N] = (0, 0)\n",
    "        logtotal = log(self.total)\n",
    "        for idx in range(N-1, -1, -1):\n",
    "            logging.debug(\"\\t idx: %s\"%idx)\n",
    "            logging.debug(\"\\t DAG[%s]: %s\"% (idx,DAG[idx]))\n",
    "            tmp = []\n",
    "            for x in DAG[idx]:\n",
    "                logging.debug(\"\\t\\t x: %s\"%x)\n",
    "                logging.debug(\"\\t\\t sentence[idx:x + 1]: %s\"%sentence[idx:x + 1])\n",
    "                # 计算概率值\n",
    "                prob = log(self.FREQ.get(sentence[idx:x + 1]) or 1) - logtotal\n",
    "                logging.debug(\"\\t\\t porb: %s\"%prob)\n",
    "                logging.debug(\"\\t\\t route[%s][0]: %s\"%(x+1, route[x+1][0]))\n",
    "                value = round(prob + route[x + 1][0],2)\n",
    "                logging.debug(\"\\t\\t value: %s\"%value)\n",
    "                tmp.append( (value, x) )\n",
    "                logging.debug(\"\\t\\t tmp: %s\"%str(tmp))\n",
    "            route[idx] = max(tmp)\n",
    "            logging.debug(\"\\t route[%s]: %s\"%(idx,str(route[idx])))\n",
    "            \n",
    "    def cut(self,sentence):\n",
    "        DAG = self.get_DAG(sentence)\n",
    "        route = {}\n",
    "        self.calc(sentence, DAG, route)\n",
    "        x = 0\n",
    "        N = len(sentence)\n",
    "        buf = ''\n",
    "        while x < N:\n",
    "            y = route[x][1] + 1\n",
    "            l_word = sentence[x:y]\n",
    "            logging.debug(\"\\tx: %s\"%x)\n",
    "            logging.debug(\"\\troute[%s][1]: %s\"%(x,route[x][1]))\n",
    "            logging.debug(\"\\ty: %s\"%y)\n",
    "            logging.debug(\"\\tl_word: %s\"%l_word)\n",
    "            # 如果是连续的英文字母或数字进行合并\n",
    "            if self.re_eng.match(l_word) and len(l_word) == 1:\n",
    "                buf += l_word\n",
    "                x = y\n",
    "            else:\n",
    "                if buf:\n",
    "                    yield buf\n",
    "                    buf = ''\n",
    "                yield l_word\n",
    "                x = y\n",
    "        # 如果句子以连续英文或数字结尾\n",
    "        if buf:\n",
    "            yield buf\n",
    "            buf = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T10:38:59.101998Z",
     "start_time": "2021-03-30T10:38:58.495594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'希腊  的  经济  结构  较  特殊  。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcut = wordCut()\n",
    "sentence = '希腊的经济结构较特殊。'\n",
    "\"  \".join(wordcut.cut(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T10:39:00.089400Z",
     "start_time": "2021-03-30T10:39:00.074440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11: (0, 0),\n",
       " 10: (-17.91, 10),\n",
       " 9: (-29.48, 9),\n",
       " 8: (-26.97, 9),\n",
       " 7: (-34.56, 7),\n",
       " 6: (-45.83, 6),\n",
       " 5: (-42.91, 6),\n",
       " 4: (-53.2, 4),\n",
       " 3: (-50.03, 4),\n",
       " 2: (-55.27, 2),\n",
       " 1: (-66.73, 1),\n",
       " 0: (-65.33, 1)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route = {}\n",
    "DAG = wordcut.get_DAG(sentence)\n",
    "wordcut.calc(sentence, DAG, route)\n",
    "route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:37:04.395405Z",
     "start_time": "2021-04-04T10:36:57.559537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e0db6729824f0aa6224f4c03a8a218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 6.150891304016113\n"
     ]
    }
   ],
   "source": [
    "wordcut = wordCut()\n",
    "\n",
    "with open(msr_test,encoding=\"utf-8\") as test, open(msr_output, 'w', encoding=\"utf-8\") as output:\n",
    "    start = time.time()\n",
    "    for line in tqdm(test):\n",
    "        sentence = line.strip()\n",
    "        output.write(\"  \".join(wordcut.cut(sentence)))\n",
    "        output.write(\"\\n\")\n",
    "    runtime = time.time()-start\n",
    "print('runtime:',runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:37:05.515415Z",
     "start_time": "2021-04-04T10:37:05.508420Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_region(segmentation: str) -> list: # 词转区间\n",
    "    region = []\n",
    "    start = 0\n",
    "    for word in re.compile(\"\\\\s+\").split(segmentation.strip()):\n",
    "        end = start + len(word)\n",
    "        region.append((start, end))\n",
    "        start = end\n",
    "    return region\n",
    "\n",
    "def prf(gold: str, pred: str, dic) -> tuple: # 准确率函数\n",
    "    A_size, B_size, A_cap_B_size, OOV, IV, OOV_R, IV_R = 0, 0, 0, 0, 0, 0, 0\n",
    "    with open(gold, encoding=\"utf-8\") as gd, open(pred, encoding=\"utf-8\") as pd:\n",
    "        for g, p in zip(gd, pd):  # 取出答案：g和预测：p\n",
    "            A, B = set(to_region(g)), set(to_region(p))  # 得到区间\n",
    "            A_size += len(A)\n",
    "            B_size += len(B)\n",
    "            A_cap_B_size += len(A & B)\n",
    "            text = re.sub(\"\\\\s+\", \"\", g)  # 得到原始文本\n",
    "            for (start, end) in A:\n",
    "                word = text[start:end]\n",
    "                if word in dic:\n",
    "                    IV += 1\n",
    "                else:\n",
    "                    OOV += 1\n",
    "\n",
    "            for (start, end) in A & B:\n",
    "                word = text[start:end]\n",
    "                if word in dic:\n",
    "                    IV_R += 1\n",
    "                else:\n",
    "                    OOV_R += 1\n",
    "    p, r = A_cap_B_size / B_size * 100, A_cap_B_size / A_size * 100\n",
    "    return p, r, 2 * p * r / (p + r), OOV_R / OOV * 100, IV_R / IV * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:37:05.997425Z",
     "start_time": "2021-04-04T10:37:05.858722Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dictionary(dict_file):\n",
    "    fr = open(dict_file,encoding=\"utf-8\")\n",
    "    word_list = [item.strip().split(\"\\t\")[0] for item in fr]\n",
    "    return set(word_list)\n",
    "\n",
    "word_dict = load_dictionary(SogouW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:37:06.444265Z",
     "start_time": "2021-04-04T10:37:06.187953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t81.88\n",
      "R:\t83.24\n",
      "F1:\t82.56\n",
      "OOV-R:\t82.59\n",
      "IV-R:\t83.87\n"
     ]
    }
   ],
   "source": [
    "print(OUTFRMAE % prf(msr_gold, msr_output, word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:37:32.412150Z",
     "start_time": "2021-04-04T10:37:32.398153Z"
    }
   },
   "outputs": [],
   "source": [
    "o = open(msr_output, encoding='utf-8')\n",
    "t = open(msr_gold, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T10:37:51.347002Z",
     "start_time": "2021-04-04T10:37:51.339023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "海运业  雄踞  全球  之  首  ，  按  吨位  计  占  世界  总数  的  １  ７  ％  。\n",
      "\n",
      "海运  业  雄踞  全球  之  首  ，  按  吨位  计  占  世界  总数  的  １７％  。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(o.readline())\n",
    "print(t.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一元语法模型\n",
    "感觉不是很复杂，就自己尝试实现了一个简单的帮助自己理解。不过写的时候基本还是参照代码写的。。离完全手写还是有很长一段距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建前缀词典 prefix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:13:38.902296Z",
     "start_time": "2021-03-27T16:13:38.892321Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_pfdict(word_dict_path, encoding='utf-8'):\n",
    "    # 千万注意这个不是对长度为N的句子取N-1个前缀，而是每个组合都可能成为前缀。这里被坑了T-T\n",
    "    word_dict_file = open(word_dict_path, encoding=encoding)\n",
    "    prefix_dict = {} # 前缀字典\n",
    "    original_dict = {} # 原始字典\n",
    "    freq_total = 0\n",
    "    for lineno, line in tqdm(enumerate(word_dict_file, 1)):\n",
    "        word, freq = line.strip().split(' ')[:2]\n",
    "        freq = int(freq)\n",
    "        original_dict[word] = freq\n",
    "        for prefix_idx in range(len(line)):\n",
    "            prefix = word[:prefix_idx + 1]\n",
    "            if prefix not in prefix_dict:  # 如果不在前缀词典内，则用0占位\n",
    "                prefix_dict[prefix] = 0\n",
    "        else:  # 这里改了一下顺序，把词的前缀放在词前面\n",
    "            freq_total += freq  # 统计词频\n",
    "            prefix_dict[word] = freq\n",
    "\n",
    "    word_dict_file.close()\n",
    "    re_dict = {  # 这样写的用意是如果有其他想要输出的属性，可以直接加到字典里，通过键来读取\n",
    "        'prefix_dict': prefix_dict,  # 前缀词典\n",
    "        'freq_total': freq_total,  # 词频\n",
    "        'original_dict':original_dict, # 原始字典\n",
    "#         'freq_lst': sorted(prefix.items(), key=lambda x: x[1], reverse=True),  # 词频降序的列表\n",
    "    }\n",
    "    return re_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:35:27.718723Z",
     "start_time": "2021-03-27T16:35:26.552724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928b8fb48a314fe79fad5288f896f41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 读取前缀词典\n",
    "re_dict = sample_pfdict(word_dict_path)\n",
    "prefix_dict = re_dict['prefix_dict']\n",
    "freq_total = re_dict['freq_total']\n",
    "original_dict = re_dict['original_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有向无环图 DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:58:34.272086Z",
     "start_time": "2021-03-27T16:58:34.254108Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_DAG(sentence, prefix_dict):\n",
    "    DAG = {}\n",
    "    N = len(sentence)\n",
    "    for start_idx in range(N):\n",
    "        idx_lst = [] # 位置索引列表\n",
    "        frag = sentence[start_idx]\n",
    "        end_idx = start_idx\n",
    "        while end_idx < N and frag in prefix_dict:\n",
    "            if prefix_dict[frag]:\n",
    "                idx_lst.append(end_idx)\n",
    "            end_idx += 1\n",
    "            frag = sentence[start_idx:end_idx+1]\n",
    "        if not idx_lst:\n",
    "            idx_lst.append(start_idx)\n",
    "        DAG[start_idx] = idx_lst\n",
    "    return DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:58:39.018861Z",
     "start_time": "2021-03-27T16:58:39.004897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1],\n",
       " 1: [1],\n",
       " 2: [2],\n",
       " 3: [3, 4],\n",
       " 4: [4],\n",
       " 5: [5, 6],\n",
       " 6: [6],\n",
       " 7: [7],\n",
       " 8: [8, 9],\n",
       " 9: [9],\n",
       " 10: [10]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_DAG(\"希腊的经济结构较特殊。\",prefix_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大概率路径 maxProbRoute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:21:59.502808Z",
     "start_time": "2021-03-27T16:21:59.486876Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_maxProbRoute(sentence, DAG, prefix_dict, freq_total):\n",
    "    route = {}\n",
    "    N = len(sentence)\n",
    "    route[N] = (0,0) # 作为结尾，防溢出\n",
    "    logtotal = log(freq_total)\n",
    "    for start_idx in range(N-1, -1, -1):\n",
    "        best_prob = float('-inf')\n",
    "        best_endidx = N-1\n",
    "        prob_sum = 0\n",
    "        for end_idx in DAG[start_idx]:\n",
    "            part_of_sentence = sentence[start_idx:end_idx+1]\n",
    "            prob = log(prefix_dict.get(part_of_sentence) or 1) - logtotal # log后累乘变累加\n",
    "            prob_sum = route[end_idx+1][0] + prob # \n",
    "            if prob_sum > best_prob:\n",
    "                best_prob = prob_sum\n",
    "                best_endidx = end_idx\n",
    "        else:\n",
    "            route[start_idx] = (best_prob, best_endidx)\n",
    "            \n",
    "    return route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:22:02.601087Z",
     "start_time": "2021-03-27T16:22:02.588127Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"去北京大学玩\"\n",
    "test_DAG = sample_DAG(sentence=sentence, original_dict=original_dict)\n",
    "maxProbRoute = sample_maxProbRoute(sentence=sentence, DAG=test_DAG, freq_total=freq_total, prefix_dict=prefix_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行分词 cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:22:06.595222Z",
     "start_time": "2021-03-27T16:22:06.587248Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_cut(sentence, maxProbRoute):\n",
    "    buf = '' # 缓冲\n",
    "    re_eng = re.compile('[a-zA-Z0-9]', re.U) # 正则\n",
    "    N = len(sentence)\n",
    "    start_idx = 0\n",
    "    while start_idx < N:\n",
    "        end_idx = maxProbRoute[start_idx][1] + 1\n",
    "        sentence_cut = sentence[start_idx:end_idx]\n",
    "        # 如果是连续的英文字母或数字进行合并\n",
    "        if re_eng.match(sentence_cut) and len(sentence_cut) == 1:\n",
    "            buf += sentence_cut\n",
    "            start_idx = end_idx\n",
    "        else:\n",
    "            if buf:\n",
    "                yield buf\n",
    "                buf = ''\n",
    "            yield sentence_cut\n",
    "            start_idx = end_idx\n",
    "    # 如果句子以连续英文或数字结尾\n",
    "    if buf:\n",
    "        yield buf\n",
    "        buf = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:59:28.357016Z",
     "start_time": "2021-03-27T16:59:28.341031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['希腊', '的', '经济', '结构', '较', '特殊', '。']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"希腊的经济结构较特殊。\"\n",
    "test_DAG = sample_DAG(sentence=sentence, prefix_dict=prefix_dict)\n",
    "maxProbRoute = sample_maxProbRoute(sentence=sentence, DAG=test_DAG, freq_total=freq_total, prefix_dict=prefix_dict)\n",
    "list(sample_cut(sentence,maxProbRoute))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建一元语法分词类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:59:50.939819Z",
     "start_time": "2021-03-27T16:59:50.927848Z"
    }
   },
   "outputs": [],
   "source": [
    "class sample_wordCut():\n",
    "    def __init__(self, word_dict_path):\n",
    "        self.word_dict_path = word_dict_path\n",
    "        self.re_dict = self._gen_pfdict(word_dict_path)\n",
    "        self.prefix_dict = self.re_dict['prefix_dict']\n",
    "        self.freq_total = self.re_dict['freq_total']\n",
    "        self.original_dict = self.re_dict['original_dict']\n",
    "    \n",
    "    def _gen_pfdict(self, word_dict_path, encoding='utf-8'):\n",
    "        pfdict = sample_pfdict(word_dict_path, encoding)\n",
    "        return pfdict\n",
    "        \n",
    "    def _get_DAG(self, sentence, original_dict):\n",
    "#         DAG = get_DAG(sentence)\n",
    "        DAG = sample_DAG(sentence, self.prefix_dict)\n",
    "        return DAG\n",
    "        \n",
    "    def _get_maxProbRoute(self, sentence, DAG, prefix_dict, freq_total):\n",
    "        maxProbRoute = sample_maxProbRoute(sentence, DAG, self.prefix_dict, self.freq_total)\n",
    "        return maxProbRoute\n",
    "        \n",
    "    def cut(self, sentence):\n",
    "        DAG = self._get_DAG(sentence, self.original_dict)\n",
    "        maxProbRoute = self._get_maxProbRoute(sentence=sentence,\n",
    "                                              DAG=DAG,\n",
    "                                              prefix_dict=self.prefix_dict,\n",
    "                                              freq_total=self.freq_total)\n",
    "        cut = list(sample_cut(sentence, maxProbRoute))\n",
    "        return cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:59:56.595165Z",
     "start_time": "2021-03-27T16:59:55.413799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ab39d2abf84a6d95bddf6e63644647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: [0, 1],\n",
       " 1: [1],\n",
       " 2: [2],\n",
       " 3: [3, 4],\n",
       " 4: [4],\n",
       " 5: [5, 6],\n",
       " 6: [6],\n",
       " 7: [7],\n",
       " 8: [8, 9],\n",
       " 9: [9],\n",
       " 10: [10]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcut = sample_wordCut(word_dict_path)\n",
    "wordcut._get_DAG( \"希腊的经济结构较特殊。\", original_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T17:00:02.812489Z",
     "start_time": "2021-03-27T17:00:01.013009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fbc8a00d6d49a58ee8442579dee3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62958e85cc854c8a92b2b5f2443b5172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 0.5596897602081299\n"
     ]
    }
   ],
   "source": [
    "wordcut = sample_wordCut(word_dict_path)\n",
    "\n",
    "with open(msr_test,encoding=\"utf-8\") as test, open(msr_output, 'w', encoding=\"utf-8\") as output:\n",
    "    start = time.time()\n",
    "    for line in tqdm(test):\n",
    "        sentence = line.strip()\n",
    "        output.write(\"  \".join(wordcut.cut(sentence)))\n",
    "        output.write(\"\\n\")\n",
    "    runtime = time.time()-start\n",
    "print('runtime:',runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T17:00:07.674676Z",
     "start_time": "2021-03-27T17:00:07.410159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t81.89\n",
      "R:\t83.24\n",
      "F1:\t82.56\n",
      "OOV-R:\t81.16\n",
      "IV-R:\t83.76\n"
     ]
    }
   ],
   "source": [
    "print(OUTFRMAE % prf(msr_gold, msr_output, word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289.275px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
