{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T13:32:05.564107Z",
     "start_time": "2021-04-05T13:32:03.423029Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyhanlp import *\n",
    "import numpy as np\n",
    "import collections\n",
    "from sys import getsizeof\n",
    "import time\n",
    "import re\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from numba import njit # 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T13:32:05.579814Z",
     "start_time": "2021-04-05T13:32:05.565851Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "sighan05 = \"./第二届国际中文分词评测/icwb2-data/\"\n",
    "SogouW = \"./SogouW/Freq/SogouLabDic.dic\"\n",
    "msr_dict = os.path.join(sighan05, 'gold', 'msr_training_words.utf8')\n",
    "# msr_test = os.path.join(sighan05, 'testing', 'msr_test.utf8') # 没用到？\n",
    "msr_output = os.path.join(sighan05, 'testing', 'msr_output.txt') # 保存输出结果的空文件\n",
    "msr_gold = os.path.join(sighan05, 'gold', 'msr_test_gold.utf8') # 正确结果\n",
    "OUTFRMAE = \"P:\\t%.2f\\nR:\\t%.2f\\nF1:\\t%.2f\\nOOV-R:\\t%.2f\\nIV-R:\\t%.2f\" # 准确性结果的输出格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T13:32:05.595828Z",
     "start_time": "2021-04-05T13:32:05.581807Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def load_dictionary(dict_file): # 加载词库\n",
    "    fr = open(dict_file,encoding=\"utf-8\")\n",
    "    word_list = [item.strip().split(\"\\t\")[0] for item in fr]\n",
    "    return set(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:21:20.214986Z",
     "start_time": "2021-03-19T08:21:20.203948Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_region(segmentation: str) -> list: # 词转区间\n",
    "    region = []\n",
    "    start = 0\n",
    "    for word in re.compile(\"\\\\s+\").split(segmentation.strip()):\n",
    "        end = start + len(word)\n",
    "        region.append((start, end))\n",
    "        start = end\n",
    "    return region\n",
    "\n",
    "def prf(gold: str, pred: str, dic) -> tuple: # 准确率函数\n",
    "    A_size, B_size, A_cap_B_size, OOV, IV, OOV_R, IV_R = 0, 0, 0, 0, 0, 0, 0\n",
    "    with open(gold, encoding=\"utf-8\") as gd, open(pred, encoding=\"utf-8\") as pd:\n",
    "        for g, p in zip(gd, pd):  # 取出答案：g和预测：p\n",
    "            A, B = set(to_region(g)), set(to_region(p))  # 得到区间\n",
    "            A_size += len(A)\n",
    "            B_size += len(B)\n",
    "            A_cap_B_size += len(A & B)\n",
    "            text = re.sub(\"\\\\s+\", \"\", g)  # 得到原始文本\n",
    "            for (start, end) in A:\n",
    "                word = text[start:end]\n",
    "                if word in dic:\n",
    "                    IV += 1\n",
    "                else:\n",
    "                    OOV += 1\n",
    "\n",
    "            for (start, end) in A & B:\n",
    "                word = text[start:end]\n",
    "                if word in dic:\n",
    "                    IV_R += 1\n",
    "                else:\n",
    "                    OOV_R += 1\n",
    "    p, r = A_cap_B_size / B_size * 100, A_cap_B_size / A_size * 100\n",
    "    return p, r, 2 * p * r / (p + r), OOV_R / OOV * 100, IV_R / IV * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T13:32:05.720876Z",
     "start_time": "2021-04-05T13:32:05.597787Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# 读取词典\n",
    "word_dict = load_dictionary(SogouW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1\n",
    "根据上面的算法流程修改前向最大匹配函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:02:08.960462Z",
     "start_time": "2021-03-19T08:02:08.952449Z"
    }
   },
   "outputs": [],
   "source": [
    "# 原函数\n",
    "def forward_segment(text, dic, longest):\n",
    "    word_list = []\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        longest_word = text[i]                      # 当前扫描位置的单字\n",
    "        for j in range(i + 1, len(text) + 1):       # 所有可能的结尾\n",
    "            word = text[i:j]                        # 从当前位置到结尾的连续字符串\n",
    "            if word in dic:                         # 在词典中\n",
    "                if len(word) > len(longest_word):   # 并且更长\n",
    "                    longest_word = word             # 则更优先输出\n",
    "        word_list.append(longest_word)              # 输出最长词\n",
    "        i += len(longest_word)                      # 正向扫描\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:02:09.958602Z",
     "start_time": "2021-03-19T08:02:09.943641Z"
    }
   },
   "outputs": [],
   "source": [
    "# 改良函数\n",
    "def forward_segment_improve(text, dic, longest):\n",
    "#     longest = len(max(dic,key=len)) # 得到最长单词的字数（不知道如何从前缀树中得到）\n",
    "#     耗时比下面的循环久多了。。\n",
    "    word_list = []\n",
    "    idx = 0\n",
    "    while idx < len(text):\n",
    "        n = len(text) - idx # 得到当前指针pi到字串末端的字数n\n",
    "        # 实现(2)\n",
    "        if n == 1: \n",
    "            break\n",
    "        elif n < longest:\n",
    "            m = n\n",
    "        else:\n",
    "            m = longest\n",
    "        # 实现(3)\n",
    "        for section in range(m,1,-1): # 区间在缩小\n",
    "            word = text[idx:idx+section]\n",
    "            if word in dic:\n",
    "                longest_word = word\n",
    "                break\n",
    "        else: # for结束时section为1，实现(b)\n",
    "            longest_word = text[idx:idx+1]\n",
    "            dic.add(longest_word)\n",
    "        word_list.append(longest_word)\n",
    "        idx += len(longest_word)\n",
    "    # 实现(4)\n",
    "    return word_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:02:10.377974Z",
     "start_time": "2021-03-19T08:02:10.348972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['江西', '鄱阳湖', '干枯', '，', '中国最大', '淡水湖', '变成', '大草原']\n",
      "['江西', '鄱阳湖', '干枯', '，', '中国最大', '淡水湖', '变成', '大草原']\n"
     ]
    }
   ],
   "source": [
    "longest = len(max(word_dict,key=len))\n",
    "print(forward_segment(\"江西鄱阳湖干枯，中国最大淡水湖变成大草原\", word_dict, longest=longest))\n",
    "print(forward_segment_improve(\"江西鄱阳湖干枯，中国最大淡水湖变成大草原\", word_dict, longest=longest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2\n",
    "对比新旧算法的处理速度。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:02:22.179532Z",
     "start_time": "2021-03-19T08:02:22.170520Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_speed_new(segment, text, dic,):\n",
    "    with open(msr_gold,encoding=\"utf-8\") as gd:\n",
    "        start_time = time.time()\n",
    "        alltext = 0 \n",
    "        for idx,g in tqdm(enumerate(gd)): \n",
    "            if idx>=10000: # 取10000条(实际只有3984条)\n",
    "                break\n",
    "            text = re.sub(\"\\\\s+\", \"\", g)\n",
    "            segment(text, dic, longest)\n",
    "            alltext += len(text)\n",
    "        else:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            seg_speed = alltext / elapsed_time / 10000\n",
    "            print('%s: %.2f 万字/秒' % (seg.__name__, seg_speed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:02:23.838607Z",
     "start_time": "2021-03-19T08:02:22.563323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38c5f6126784553a090b051a1c5550e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_segment: 21.05 万字/秒\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65571c386f9b46b5be4511dd011e649d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_segment_improve: 48.51 万字/秒\n"
     ]
    }
   ],
   "source": [
    "# 仅使用一条文本进行重复发现速度浮动很大，不能正确表示速度，这里使用\n",
    "text = \"江西鄱阳湖干枯，中国最大淡水湖变成大草原\"\n",
    "segments = [forward_segment,forward_segment_improve]\n",
    "res = []\n",
    "for seg in segments:\n",
    "    res.append((seg.__name__, evaluate_speed_new(seg, text, word_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试了几次发现浮动不大，应该是比较符合真实情况的测试。\n",
    "- 这里可以发现改进后的方法确实有一定程度的提高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他一些测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 字典树使用改进后的前向匹配算法的速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:02:47.377704Z",
     "start_time": "2021-03-19T08:02:47.358713Z"
    }
   },
   "outputs": [],
   "source": [
    "# 字典树\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = {}  # 用字典构建树结构\n",
    "        self.end_of_word = '#'  # 用#标志一个单词的结束\n",
    "\n",
    "    def insert(self, word: str):\n",
    "        node = self.root\n",
    "        for char in word:  # 按word的每个字符搜索\n",
    "            node = node.setdefault(char, {})\n",
    "            # 如果找到对应字符，进入该字符的分支；如果没有则新建分支，继续生长\n",
    "        node[self.end_of_word] = self.end_of_word  # 添加结束符\n",
    "\n",
    "    # 查找一个单词是否完整的在字典树里，所以最后一句判断结束符是否在node中\n",
    "    def search(self, word: str):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node:\n",
    "                return False\n",
    "            node = node[char]  # 进入分支\n",
    "        return self.end_of_word in node\n",
    "\n",
    "    def __contains__(self, word):\n",
    "        \"\"\"\n",
    "        实现魔术方法，可以使用in或not in判断word是否在树中\n",
    "        \"\"\"\n",
    "        return self.search(word)\n",
    "\n",
    "    # 查找是否有一个单词是这个前缀开始的\n",
    "    def startsWith(self, prefix: str):\n",
    "        node = self.root\n",
    "        for char in prefix:\n",
    "            if char not in node:\n",
    "                return False\n",
    "            node = node[char]\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:02:48.106714Z",
     "start_time": "2021-03-19T08:02:47.802496Z"
    }
   },
   "outputs": [],
   "source": [
    "trie_tree = Trie()\n",
    "for word in word_dict:\n",
    "    trie_tree.insert(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:02:53.336533Z",
     "start_time": "2021-03-19T08:02:53.330487Z"
    }
   },
   "outputs": [],
   "source": [
    "# 针对字典树修改的前向匹配函数\n",
    "def forward_segment_improve_tree(text, dic, longest):\n",
    "#     longest = len(max(dic,key=len)) # 得到最长单词的字数（不知道如何从前缀树中得到）\n",
    "#     耗时比下面的循环久多了。。\n",
    "    word_list = []\n",
    "    idx = 0\n",
    "    while idx < len(text):\n",
    "        n = len(text) - idx # 得到当前指针pi到字串末端的字数n\n",
    "        # 实现(2)\n",
    "        if n == 1: \n",
    "            break\n",
    "        elif n < longest:\n",
    "            m = n\n",
    "        else:\n",
    "            m = longest\n",
    "        # 实现(3)\n",
    "        for section in range(m,1,-1): # 区间在缩小\n",
    "            word = text[idx:idx+section]\n",
    "            if word in dic:\n",
    "                longest_word = word\n",
    "                break\n",
    "        else: # for结束时section为1，实现(b)\n",
    "            longest_word = text[idx:idx+1]\n",
    "            dic.insert(longest_word) # 此处做了修改：插入到字典树内\n",
    "        word_list.append(longest_word)\n",
    "        idx += len(longest_word)\n",
    "    # 实现(4)\n",
    "    return word_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:03:08.773451Z",
     "start_time": "2021-03-19T08:03:05.551197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc1e8bc6723462981d9b12cb4bec7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_segment: 7.88 万字/秒\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb28ca49a39e4356ace7064f0e650508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_segment_improve_tree: 21.04 万字/秒\n"
     ]
    }
   ],
   "source": [
    "segments = [forward_segment,forward_segment_improve_tree]\n",
    "res = []\n",
    "for seg in segments:\n",
    "    res.append((seg.__name__, evaluate_speed_new(seg, text, trie_tree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准确率测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:24:01.055131Z",
     "start_time": "2021-03-19T08:24:01.043163Z"
    }
   },
   "outputs": [],
   "source": [
    "runtime = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:24:09.108082Z",
     "start_time": "2021-03-19T08:24:09.100119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.940832614898682"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:26:42.859863Z",
     "start_time": "2021-03-19T08:26:41.677434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t73.60\n",
      "R:\t72.75\n",
      "F1:\t73.17\n",
      "OOV-R:\t0.00\n",
      "IV-R:\t76.31\n",
      "Time:\t0.96\n"
     ]
    }
   ],
   "source": [
    "# forward_segment\n",
    "with open(msr_gold,encoding=\"utf-8\") as test, open(msr_output, 'w', encoding=\"utf-8\") as output:\n",
    "    start = time.time()\n",
    "    for line in test:\n",
    "        output.write(\"  \".join(forward_segment(re.sub(\"\\\\s+\", \"\", line), word_dict, longest)))\n",
    "        output.write(\"\\n\")\n",
    "    runtime = time.time()-start\n",
    "print(OUTFRMAE % prf(msr_gold, msr_output, word_dict))\n",
    "print(\"Time:\\t%.2f\" % runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:27:03.933357Z",
     "start_time": "2021-03-19T08:27:03.364550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t72.66\n",
      "R:\t69.23\n",
      "F1:\t70.90\n",
      "OOV-R:\t0.00\n",
      "IV-R:\t72.62\n",
      "Time:\t0.36\n"
     ]
    }
   ],
   "source": [
    "# forward_segment_improve\n",
    "with open(msr_gold,encoding=\"utf-8\") as test, open(msr_output, 'w', encoding=\"utf-8\") as output:\n",
    "    start = time.time()\n",
    "    for line in test:\n",
    "        output.write(\"  \".join(forward_segment_improve(re.sub(\"\\\\s+\", \"\", line), word_dict, longest)))\n",
    "        output.write(\"\\n\")\n",
    "    runtime = time.time()-start\n",
    "print(OUTFRMAE % prf(msr_gold, msr_output, word_dict))\n",
    "print(\"Time:\\t%.2f\" % runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:27:18.404089Z",
     "start_time": "2021-03-19T08:27:17.276166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t72.66\n",
      "R:\t69.23\n",
      "F1:\t70.90\n",
      "OOV-R:\t0.00\n",
      "IV-R:\t72.62\n",
      "Time:\t0.84\n"
     ]
    }
   ],
   "source": [
    "# forward_segment_improve_tree\n",
    "with open(msr_gold,encoding=\"utf-8\") as test, open(msr_output, 'w', encoding=\"utf-8\") as output:\n",
    "    start = time.time()\n",
    "    for line in test:\n",
    "        output.write(\"  \".join(forward_segment_improve_tree(re.sub(\"\\\\s+\", \"\", line), trie_tree, longest)))\n",
    "        output.write(\"\\n\")\n",
    "    runtime = time.time()-start\n",
    "print(OUTFRMAE % prf(msr_gold, msr_output, trie_tree))\n",
    "print(\"Time:\\t%.2f\" % runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:不知道为啥，这里的测试结果和课件里的结果不一致，低好多。。然后改良的算法比原来的准确率还低一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289.275px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
