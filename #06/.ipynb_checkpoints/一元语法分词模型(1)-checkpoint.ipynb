{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一元语法模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前缀词典构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pfdict(f):\n",
    "    lfreq = {}\n",
    "    ltotal = 0\n",
    "    for lineno, line in enumerate(f, 1):\n",
    "        try:\n",
    "            line = line.strip()\n",
    "            word, freq = line.split(' ')[:2]\n",
    "            freq = int(freq)\n",
    "            lfreq[word] = freq\n",
    "            ltotal += freq\n",
    "            for ch in range(len(word)):\n",
    "                wfrag = word[:ch + 1]\n",
    "                if wfrag not in lfreq:\n",
    "                    lfreq[wfrag] = 0 # 不在词典里的前缀，词频设为零，前提是词典已经进行排序\n",
    "        except ValueError:\n",
    "            raise ValueError(\n",
    "                'invalid dictionary entry in %s at Line %s: %s' % (f.name, lineno, line))\n",
    "    f.close()\n",
    "    return lfreq, ltotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有向无环图构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - [line:%(lineno)d] - %(levelname)s: %(message)s')\n",
    "\n",
    "f = open(\"jieba_dict.txt\",encoding=\"utf-8\")\n",
    "FREQ, total = gen_pfdict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FREQ['北京']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DAG(sentence,FREQ):\n",
    "    logging.debug(\"生成有向无环图...\")\n",
    "    DAG = {}\n",
    "    N = len(sentence)\n",
    "    for k in range(N):\n",
    "        logging.debug(\"k = %s\"%k)\n",
    "        tmplist = []\n",
    "        i = k\n",
    "        frag = sentence[k]\n",
    "        logging.debug(\"for 循环 frag: %s\"%frag)\n",
    "        while i < N and frag in FREQ:\n",
    "            logging.debug(\"\\t 进入while...\")\n",
    "            logging.debug(\"\\t i = %s\"%i)\n",
    "            logging.debug(\"\\t FREQ[%s]: %s\"%(frag,FREQ[frag]))\n",
    "            if FREQ[frag]:\n",
    "                tmplist.append(i)\n",
    "            i += 1\n",
    "            frag = sentence[k:i + 1]\n",
    "            logging.debug(\"\\t while 循环 frag: %s\"%frag)\n",
    "            logging.debug(\"\\t tmplist: %s\"%tmplist)\n",
    "        if not tmplist:\n",
    "            tmplist.append(k)\n",
    "            logging.debug(\"\\t if 语句 tmplist: %s\"%tmplist)\n",
    "        DAG[k] = tmplist\n",
    "    return DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大概率路径计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6: (0, 0), 5: (-9.57, 5), 4: (-17.71, 4), 3: (-17.58, 4), 2: (-26.7, 2), 1: (-19.85, 4), 0: (-26.04, 0)}\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO) \n",
    "\n",
    "def calc(sentence, DAG, total, route):\n",
    "    logging.debug(\"计算路径概率...\")\n",
    "    N = len(sentence)\n",
    "    route[N] = (0, 0)\n",
    "    logtotal = log(total)\n",
    "    for idx in range(N-1, -1, -1):\n",
    "        logging.debug(\"\\t idx: %s\"%idx)\n",
    "        logging.debug(\"\\t DAG[%s]: %s\"% (idx,DAG[idx]))\n",
    "        tmp = []\n",
    "        for x in DAG[idx]:\n",
    "            logging.debug(\"\\t\\t x: %s\"%x)\n",
    "            logging.debug(\"\\t\\t sentence[idx:x + 1]: %s\"%sentence[idx:x + 1])\n",
    "            # 计算概率值\n",
    "            prob = log(FREQ.get(sentence[idx:x + 1]) or 1) - logtotal\n",
    "            logging.debug(\"\\t\\t porb: %s\"%prob)\n",
    "            logging.debug(\"\\t\\t route[%s][0]: %s\"%(x+1, route[x+1][0]))\n",
    "            value = round(prob + route[x + 1][0],2)\n",
    "            logging.debug(\"\\t\\t value: %s\"%value)\n",
    "            tmp.append( (value, x) )\n",
    "            logging.debug(\"\\t\\t tmp: %s\"%str(tmp))\n",
    "        route[idx] = max(tmp)\n",
    "        logging.debug(\"\\t route[%s]: %s\"%(idx,str(route[idx])))\n",
    "\n",
    "\n",
    "route = {}\n",
    "sentence = \"去北京大学玩\"\n",
    "DAG = get_DAG(sentence,FREQ)\n",
    "calc(sentence, DAG, total, route)            \n",
    "print(route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取分词结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 精确模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试图将句子最精确地切开，适合文本分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['去', '北京大学', '玩']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re_eng = re.compile('[a-zA-Z0-9]', re.U)\n",
    "\n",
    "def __cut_DAG_NO_HMM(sentence, FREQ, total):\n",
    "    DAG = get_DAG(sentence,FREQ)\n",
    "    route = {}\n",
    "    calc(sentence, DAG, total, route)\n",
    "    x = 0\n",
    "    N = len(sentence)\n",
    "    buf = ''\n",
    "    while x < N:\n",
    "        y = route[x][1] + 1\n",
    "        l_word = sentence[x:y]\n",
    "        logging.debug(\"\\tx: %s\"%x)\n",
    "        logging.debug(\"\\troute[%s][1]: %s\"%(x,route[x][1]))\n",
    "        logging.debug(\"\\ty: %s\"%y)\n",
    "        logging.debug(\"\\tl_word: %s\"%l_word)\n",
    "        # 如果是连续的英文字母或数字进行合并\n",
    "        if re_eng.match(l_word) and len(l_word) == 1:\n",
    "            buf += l_word\n",
    "            x = y\n",
    "        else:\n",
    "            if buf:\n",
    "                yield buf\n",
    "                buf = ''\n",
    "            yield l_word\n",
    "            x = y\n",
    "    # 如果句子以连续英文或数字结尾\n",
    "    if buf:\n",
    "        yield buf\n",
    "        buf = ''\n",
    "        \n",
    "list(__cut_DAG_NO_HMM(sentence,FREQ,total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['项目', '的', '研究']\n",
      "['商品', '和', '服务']\n",
      "['研究', '生命', '起源']\n",
      "['当', '下雨天', '地面', '积水']\n",
      "['结婚', '的', '和', '尚未', '结婚', '的']\n",
      "['欢迎', '新', '老师', '生前', '来', '就餐']\n"
     ]
    }
   ],
   "source": [
    "# 测试例子\n",
    "test_cases = ['项目的研究',\n",
    "              '商品和服务',\n",
    "              '研究生命起源',\n",
    "              '当下雨天地面积水',\n",
    "              '结婚的和尚未结婚的',\n",
    "              '欢迎新老师生前来就餐']\n",
    "\n",
    "logger.setLevel(logging.INFO) \n",
    "\n",
    "for case in test_cases:\n",
    "    print(list(__cut_DAG_NO_HMM(case, FREQ, total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习：\n",
    "\n",
    "对一元语法分词器的性能在MSR语料库上进行评测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准确率测评"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sighan05 = \"第二届国际中文分词评测/icwb2-data/\"\n",
    "msr_dict = os.path.join(sighan05, 'gold', 'msr_training_words.utf8')\n",
    "msr_train = os.path.join(sighan05, 'training','msr_training.utf8')\n",
    "msr_test = os.path.join(sighan05, 'testing', 'msr_test.utf8')\n",
    "msr_gold = os.path.join(sighan05, 'gold', 'msr_test_gold.utf8')\n",
    "msr_output = os.path.join(sighan05, 'testing', 'msr_output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:81.88 R:83.24 F1:82.56 OOV-R:81.16 IV-R:83.75\n"
     ]
    }
   ],
   "source": [
    "from common import *\n",
    "def load_dictionary(dict_file):\n",
    "    \"\"\"\n",
    "    加载词库\n",
    "    :return: 一个set形式的词库\n",
    "    \"\"\"\n",
    "    fr = open(dict_file,encoding=\"utf-8\")\n",
    "    word_list = [item.strip().split(\" \")[0] for item in fr]\n",
    "    return set(word_list)\n",
    "\n",
    "word_dict = load_dictionary(\"jieba_dict.txt\")\n",
    "\n",
    "with open(msr_test,encoding=\"utf-8\") as test, open(msr_output, 'w', encoding=\"utf-8\") as output:\n",
    "    for line in test:\n",
    "        output.write(\"  \".join(list(__cut_DAG_NO_HMM(line.strip(), FREQ, total))))\n",
    "        output.write(\"\\n\")\n",
    "        \n",
    "print(\"P:%.2f R:%.2f F1:%.2f OOV-R:%.2f IV-R:%.2f\" % prf(msr_gold, msr_output, word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:82.00 R:83.35 F1:82.67 OOV-R:81.31 IV-R:83.86\n"
     ]
    }
   ],
   "source": [
    "with open(msr_gold,encoding=\"utf-8\") as test, open(msr_output, 'w', encoding=\"utf-8\") as output:\n",
    "    for line in test:\n",
    "        output.write(\"  \".join(list(__cut_DAG_NO_HMM(re.sub(\"\\\\s+\", \"\", line), FREQ, total))))\n",
    "        output.write(\"\\n\")\n",
    "print(\"P:%.2f R:%.2f F1:%.2f OOV-R:%.2f IV-R:%.2f\" % prf(msr_gold, msr_output, word_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析造成不同结果的原因"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现上面用msr_gold语料和msr_test语料的评测结果略有不同，我们把两个语料中不同的句子进行输出。发现造成不同的原因是多一个或少一个引号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在对“东方红三号”卫星的测控过程中，西安卫星测控中心首次采用同国际标准兼容的新型测控网，对卫星成功地实施了３次变轨和多次定点捕获进行轨道修正。“\n",
      "在对“东方红三号”卫星的测控过程中，西安卫星测控中心首次采用同国际标准兼容的新型测控网，对卫星成功地实施了３次变轨和多次定点捕获进行轨道修正。\n",
      "\n",
      "远望号”航天远洋测量船实现了从海上测量到测控的新跨越。\n",
      "“远望号”航天远洋测量船实现了从海上测量到测控的新跨越。\n",
      "\n",
      "去年以来，这个工段各个班组的日核算从未间断过，经济效益与日俱增。“\n",
      "去年以来，这个工段各个班组的日核算从未间断过，经济效益与日俱增。\n",
      "\n",
      "整天算帐，烦不烦？”\n",
      "“整天算帐，烦不烦？”\n",
      "\n",
      "记者问正在现场忙碌的工人。“\n",
      "记者问正在现场忙碌的工人。\n",
      "\n",
      "烦也得算！”\n",
      "“烦也得算！”\n",
      "\n",
      "建材公司电焊工苗磊，参加工作不足６年，先后参加过５７座大罐的施工，各种焊口达两万多道，焊缝１万多延长米，合格率达１００％，优良率达９５％以上。“\n",
      "建材公司电焊工苗磊，参加工作不足６年，先后参加过５７座大罐的施工，各种焊口达两万多道，焊缝１万多延长米，合格率达１００％，优良率达９５％以上。\n",
      "\n",
      "说主人话，干主人活，尽主人责”，已成为百里油田的一道风景线。\n",
      "“说主人话，干主人活，尽主人责”，已成为百里油田的一道风景线。\n",
      "\n",
      "农安、榆树、公主岭、梨树等产粮大县（市），发挥粮多优势，采取得力措施建设生产、防疫、加工、销售四位一体的“生猪工程”、“肉牛工程”，取得了长足进展。\n",
      "农安、榆树、公主岭、梨树等产粮大县（市），发挥粮多优势，采取得力措施建设生产、防疫、加工、销售四位 一体的“生猪工程”、“肉牛工程”，取得了长足进展。\n",
      "\n",
      "在演马庄矿百米井下工作面，记者见到了正在挥锨装煤的矿党委书记张天福和矿长杨西平。“\n",
      "在演马庄矿百米井下工作面，记者见到了正在挥锨装煤的矿党委书记张天福和矿长杨西平。\n",
      "\n",
      "工人三班倒，班班见领导”，这是去年以来全局开始形成的制度，７个矿６０多名矿领导每月都坚持下井１５个班以上。\n",
      "“工人三班倒，班班见领导”，这是去年以来全局开始形成的制度，７个矿６０多名矿领导每月都坚持下井１５个班以上。\n",
      "\n",
      "---河区人堵水道，水才冲人路。“\n",
      "---河区人堵水道，水才冲人路。\n",
      "\n",
      "岁岁防洪不见洪”麻痹了人们的防洪意识，新建的企业和房屋把河道侵占的越来越窄，造成阻水分流，加重了灾情。\n",
      "“岁岁防洪不见洪”麻痹了人们的防洪意识，新建的企业和房屋把河道侵占的越来越窄，造成阻水分流，加重了灾情。\n",
      "\n",
      "新华社北京７月１３日电（中央人民广播电台记者刘振英、新华社记者李安定）由国务院召开的全国粮食购销工作会议７月９日至１１日在北京举行。\n",
      "新华社北京７月１３日电（中央人民广播电台记者刘振英、新华社记者李安定）由国务院召开的全国粮食购销工作会议 ７月９日至１１日在北京举行。\n",
      "\n",
      "从１９７８年到１９９６年，在改革开放的大潮中，秦家山村经过１８年的艰苦拼搏，总产值由２０万元递增到３.４亿元，人均纯收入由１００来元提高到７０００元，一跃成为村庄城镇化、管理企业化的富裕文明的“小康村”、“亿元村”，成为社会主义新农村。\n",
      "从 １９７８年到１９９６年，在改革开放的大潮中，秦家山村经过１８年的艰苦拼搏，总产值由２０万元递增到３.４亿元，人均纯收入由１００来元提高到７０００元，一跃成为村庄城镇化、管理企业化的富裕文明的“小康村”、“亿元村”，成为社会主义新农村。\n",
      "\n",
      "与此相反，全省小氮肥企业将由５７家减至４５家，磷肥企业由４４家减至３５家，４０家橡胶厂也将减少一半。“\n",
      "与此相反，全省小氮肥企业将由５７家减至４５家，磷肥企业由４４家减至３５家，４０家橡胶厂也将减少一半。\n",
      "\n",
      "八五”以来，全省化工行业实现利税和利润年均递增１１.５９％和１５.８％。\n",
      "“八五”以来，全省化工行业实现利税和利润年均递增１１.５９％和１５.８％。\n",
      "\n",
      "目前，“彩虹”彩管已占国内市场的１／３，国产化率达到８０％以上。“\n",
      "目前，“彩虹”彩管已占国内市场的１／３，国产化率达到８０％以上。\n",
      "\n",
      "长虹”、“熊猫”彩电，“海尔”冰箱，“小天鹅”洗衣机，“春兰”空调等国产名牌产品，也都积极引进消化国外先进技术，为己所用，增强了竞争实力。\n",
      "“长虹”、“熊猫”彩电，“海尔”冰箱，“小天鹅”洗衣机，“春兰”空调等国产名牌产品，也都积极引进消化国外先进技术，为己所用，增强了竞争实力。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(msr_gold,encoding=\"utf-8\") as gold,open(msr_test,encoding=\"utf-8\") as test:\n",
    "    gold_lines = gold.readlines()\n",
    "    test_lines = test.readlines()\n",
    "    for i in range(len(gold_lines)):\n",
    "        if re.sub(\"\\\\s+\", \"\", gold_lines[i]) != test_lines[i].strip():\n",
    "            print(re.sub(\"\\\\s+\", \"\", gold_lines[i]))\n",
    "            print(test_lines[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能评测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9887.56 万字/秒\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9887.562470532768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "def evaluate_speed(text):\n",
    "    start_time = time.time()\n",
    "    for i in range(pressure):\n",
    "        __cut_DAG_NO_HMM(text,FREQ, total)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    seg_speed = len(text) * pressure / 10000 / elapsed_time\n",
    "    print('%.2f 万字/秒' % (seg_speed))\n",
    "    return seg_speed\n",
    "\n",
    "text = \"江西鄱阳湖干枯，中国最大淡水湖变成大草原\"\n",
    "pressure = 10000\n",
    "evaluate_speed(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
