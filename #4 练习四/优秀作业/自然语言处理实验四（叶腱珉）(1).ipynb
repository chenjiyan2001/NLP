{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<center><font size=5 face=雅黑> 自然语言处理（实验四） </font></center>  \n",
    "<br/>\n",
    "<center><font size=4 face=雅黑> 隐马尔可夫模型分词 </font></center>  \n",
    "<br/>\n",
    "<center><font size=3 face=雅黑> 18大数据 叶腱珉 180110950330 </font></center>  \n",
    "<br/>\n",
    "<center><font size=3 face=雅黑> 2021 年 3 月 31 日 </font></center> \n",
    "<br/>  \n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习要求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用MSR语料计算初始状态概率向量$\\pi$,状态转移概率矩阵$A$和发射概率矩阵$B$,构建分词器并进行性能评测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词器构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要的模块和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import os,sys\n",
    "from math import log\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "sighan05 = \"C:/Users/叶腱珉/Desktop/Natural Language Processing/实验二\\\n",
    "/第二届国际中文分词评测/icwb2-data/\"\n",
    "msr_train = os.path.join(sighan05,\"training\",\"msr_training.txt\")\n",
    "\n",
    "train_list = []      # 训练数据\n",
    "with open(msr_train,'r') as train:\n",
    "    for i in train:\n",
    "        train_list.append(re.sub('\\n','',i).strip())\n",
    "while '' in train_list:\n",
    "    train_list.remove('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建序列标注函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tagging(sentence):\n",
    "    sentence_list = sentence.split()\n",
    "    sentence_BMSE_list = [''.join(word) for word in [BMSE_tagging(word) for word in sentence_list]]\n",
    "    return ' '.join(sentence_BMSE_list)\n",
    "\n",
    "BMSE_dict = {1:['S'],2:['B','E']}\n",
    "def BMSE_tagging(word):\n",
    "    N = len(word)\n",
    "    try:\n",
    "        return BMSE_dict[N]\n",
    "    except:\n",
    "        if N < 1:\n",
    "            return \"ERROR\"\n",
    "        else:\n",
    "            return ['B']+['M']*(N-2)+['E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“  人们  常  说  生活  是  一  部  教科书  ，  而  血  与  火  的  战争  更  是  不可多得  的  教科书  ，  她  确实  是  名副其实  的  ‘  我  的  大学  ’  。 \n",
      "\n",
      "\n",
      " S BE S S BE S S S BME S S S S S S BE S S BMME S BME S S BE S BMME S S S S BE S S\n"
     ]
    }
   ],
   "source": [
    "# 测试序列标注结果\n",
    "msr_BMSE_list = [sentence_tagging(sentence) for sentence in train_list]\n",
    "\n",
    "print(train_list[0],'\\n')\n",
    "print(\"\\n\",msr_BMSE_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用MSR语料计算初始状态概率向量 𝜋 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bmse_freq(BMSE_frequency):\n",
    "    prob_list = {}\n",
    "    sum1 = sum(BMSE_frequency.values())\n",
    "    for key,value in BMSE_frequency.items():\n",
    "        prob_list[key]=log(value/sum1)\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': -1.1894065754192553,\n",
       " 'B': -0.3629831561081316,\n",
       " 'M': -3.14e+100,\n",
       " 'E': -3.14e+100}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 概率值都是取对数之后的结果\n",
    "MIN_FLOAT = -3.14e100\n",
    "\n",
    "# 利用MSR语料的标注序列，统计BMSE频数，计算初始状态概率向量\n",
    "msr_prob_start = calc_bmse_freq( Counter([i[0:1] for i in msr_BMSE_list]))\n",
    "# 由于初始状态只能是B或者S，故将M和E的初始状态概率设置为很小\n",
    "msr_prob_start['M'] = MIN_FLOAT\n",
    "msr_prob_start['E'] = MIN_FLOAT\n",
    "\n",
    "# 初始状态概率向量\n",
    "msr_prob_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  利用MSR语料计算状态转移概率矩阵 𝐴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'SB': 600115,\n",
       "         'BE': 1039906,\n",
       "         'ES': 659674,\n",
       "         'SS': 427204,\n",
       "         'BM': 215149,\n",
       "         'ME': 215149,\n",
       "         'MM': 211874,\n",
       "         'EB': 594480})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除原序列标注句子中的空格\n",
    "msr_BMSE_list1 = [re.sub(\" \",\"\",sentence) for sentence in msr_BMSE_list]\n",
    "\n",
    "# 计算所有前后两序列组合的频率\n",
    "msr_trans_list = [sentence[i:i+2] for sentence in msr_BMSE_list1 for i in range(len(sentence)-1)]\n",
    "msr_trans_count = Counter(msr_trans_list)\n",
    "\n",
    "# 统计序列频数并生成字典\n",
    "msr_trans_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': {'B': -0.5375864716182832, 'S': -0.8774461242373575},\n",
       " 'B': {'E': -0.18804907187170708, 'M': -1.763603863953054},\n",
       " 'E': {'S': -0.6424707470719607, 'B': -0.7465294468210316},\n",
       " 'M': {'E': -0.6855070645928693, 'M': -0.7008461175870558}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计序列频数生成字典后计算转移概率矩阵\n",
    "def calc_prob_trans(BMSE_frequency):\n",
    "    prob_list = {}\n",
    "    BMSE_frequency.keys()\n",
    "    for key,value in BMSE_frequency.items():\n",
    "        if key[0] not in BMSE_frequency.keys():\n",
    "            prob_list.setdefault(key[0],{})\n",
    "        prob_list[key[0]][key[1]] = value\n",
    "    for key in prob_list.keys():\n",
    "        prob_list[key] = calc_bmse_freq(prob_list[key])\n",
    "    return prob_list\n",
    "\n",
    "# 状态转移概率矩阵\n",
    "msr_prob_trans = calc_prob_trans(Counter(msr_trans_count))\n",
    "msr_prob_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用MSR语料计算发射概率矩阵 𝐵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建单字列表\n",
    "msr_words_list = [re.sub(\" \",\"\",sentence) for sentence in train_list]\n",
    "msr_words_list = list(''.join(msr_words_list))\n",
    "# 构建单词序列表\n",
    "msr_BMSE_words_list = [re.sub(\" \",\"\",sentence) for sentence in msr_BMSE_list]\n",
    "msr_BMSE_words_list = list(''.join(msr_BMSE_words_list))\n",
    "# 单字和单词序列拼接组合\n",
    "combineList = list(zip(msr_BMSE_words_list,msr_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['B', 'M', 'S', 'E'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('人', -4.868080392268559),\n",
       " ('生', -5.37793919851509),\n",
       " ('教', -5.731291675852302),\n",
       " ('战', -6.44178749474686),\n",
       " ('不', -4.591680504132731)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msr_prob_emit = {}  # 发射概率矩阵\n",
    "BMSE_list = list(\"BMSE\")\n",
    "for f in BMSE_list:\n",
    "    # 构建二级字典\n",
    "    msr_prob_emit.setdefault(f,{})\n",
    "    # 筛选出某个词序的所有发射结果\n",
    "    combineList_temp = [zip_i for zip_i in combineList if zip_i[0] == f]\n",
    "    # 统计词序频数，并计算发射概率\n",
    "    calc_emit = calc_bmse_freq(dict(Counter(combineList_temp)))\n",
    "    for key,value in calc_emit.items():\n",
    "        # 发射概率矩阵写入\n",
    "        msr_prob_emit[key[0]][key[1]] = value\n",
    "\n",
    "# 一级字典keys\n",
    "print(msr_prob_emit.keys())\n",
    "# 部分结果显示，如取序列标注为B的前五个词的发射概率结果\n",
    "list(msr_prob_emit['B'].items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建利用msr语料计算得到初始参数的HMM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrevStatus = {\n",
    "    'B': 'ES',\n",
    "    'M': 'MB',\n",
    "    'S': 'SE',\n",
    "    'E': 'BM'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-30.294867244593323, ['B', 'E', 'S', 'B', 'E'])\n"
     ]
    }
   ],
   "source": [
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    V = [{}]  # tabular\n",
    "    path = {}\n",
    "    for y in states:  # init\n",
    "        V[0][y] = start_p[y] + emit_p[y].get(obs[0], MIN_FLOAT)\n",
    "        path[y] = [y]\n",
    "\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({})\n",
    "        newpath = {}\n",
    "        for y in states:\n",
    "            em_p = emit_p[y].get(obs[t], MIN_FLOAT)\n",
    "            (prob, state) = max(\n",
    "                [(V[t - 1][y0] + trans_p[y0].get(y, MIN_FLOAT) + em_p, y0) for y0 in PrevStatus[y]])\n",
    "            V[t][y] = prob\n",
    "            newpath[y] = path[state] + [y]\n",
    "        path = newpath\n",
    "\n",
    "    (prob, state) = max((V[len(obs) - 1][y], y) for y in 'ES')\n",
    "\n",
    "    return (prob, path[state])\n",
    "\n",
    "sentence = \"商品和服务\"\n",
    "print(viterbi(sentence, \"BMES\", msr_prob_start, msr_prob_trans, msr_prob_emit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['商品', '和', '服务']\n"
     ]
    }
   ],
   "source": [
    "def __cut(sentence):\n",
    "    global emit_P\n",
    "    prob, pos_list = viterbi(sentence, 'BMES', msr_prob_start, msr_prob_trans, msr_prob_emit)\n",
    "    begin, nexti = 0, 0\n",
    "    # print pos_list, sentence\n",
    "    for i, char in enumerate(sentence):\n",
    "        pos = pos_list[i]\n",
    "        if pos == 'B':\n",
    "            begin = i\n",
    "        elif pos == 'E':\n",
    "            yield sentence[begin:i + 1]\n",
    "            nexti = i + 1\n",
    "        elif pos == 'S':\n",
    "            yield char\n",
    "            nexti = i + 1\n",
    "    if nexti < len(sentence):\n",
    "        yield sentence[nexti:]\n",
    "print(list(__cut(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能评测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary(dict_file):\n",
    "    \"\"\"\n",
    "    加载词库\n",
    "    :return: 一个set形式的词库\n",
    "    \"\"\"\n",
    "    fr = open(dict_file,encoding=\"utf-8\")\n",
    "    word_list = [item.strip().split(\"\\t\")[0] for item in fr]\n",
    "    return set(word_list)    # 以集合形式加载，实现去重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_region(segmentation: str) -> list:\n",
    "    \"\"\"\n",
    "    将分词结果转换为区间\n",
    "    :param segmentation: 商品 和 服务\n",
    "    :return: [(0, 2), (2, 3), (3, 5)]\n",
    "    \"\"\"\n",
    "    region = []\n",
    "    start = 0\n",
    "    for word in re.compile(\"\\\\s+\").split(segmentation.strip()):\n",
    "        end = start + len(word)\n",
    "        region.append((start, end)) \n",
    "        start = end\n",
    "    return region\n",
    "\n",
    "\n",
    "def prf(gold: str, pred: str, dic) -> tuple:\n",
    "    \"\"\"\n",
    "    计算P、R、F1\n",
    "    :param gold: 标准答案文件，比如“商品 和 服务”\n",
    "    :param pred: 分词结果文件，比如“商品 和服 务”\n",
    "    :param dic: 词典\n",
    "    :return: (P, R, F1, OOV_R, IV_R)\n",
    "    \"\"\"\n",
    "    A_size, B_size, A_cap_B_size, OOV, IV, OOV_R, IV_R = 0, 0, 0, 0, 0, 0, 0\n",
    "    with open(gold,encoding=\"utf-8\") as gd, open(pred,encoding=\"utf-8\") as pd:\n",
    "        for g, p in zip(gd, pd):\n",
    "            A, B = set(to_region(g)), set(to_region(p))\n",
    "            A_size += len(A)\n",
    "            B_size += len(B)\n",
    "            A_cap_B_size += len(A & B)\n",
    "            text = re.sub(\"\\\\s+\", \"\", g)\n",
    "            for (start, end) in A:\n",
    "                word = text[start: end]\n",
    "                if word in dic:\n",
    "                    IV += 1\n",
    "                else:\n",
    "                    OOV += 1\n",
    "\n",
    "            for (start, end) in A & B:\n",
    "                word = text[start: end]\n",
    "                if word in dic:\n",
    "                    IV_R += 1\n",
    "                else:\n",
    "                    OOV_R += 1\n",
    "    p, r = A_cap_B_size / B_size * 100, A_cap_B_size / A_size * 100\n",
    "    return p, r, 2 * p * r / (p + r), OOV_R / OOV * 100, IV_R / IV * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr_output = os.path.join(sighan05, 'testing', 'msr_output.txt')\n",
    "msr_gold = os.path.join(sighan05, 'gold', 'msr_test_gold.utf8')\n",
    "\n",
    "word_dict = load_dictionary(\"C:/Users/叶腱珉/Desktop/Natural Language Processing/\\\n",
    "实验二/SogouW/Freq/SogouLabDic.dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:78.03 R:80.05 F1:79.03 OOV-R:77.23 IV-R:82.81\n",
      "runtime:1.3085010051727295s\n"
     ]
    }
   ],
   "source": [
    "with open(msr_gold, encoding=\"utf-8\") as test, open(msr_output, 'w', encoding=\"utf-8\") as output:\n",
    "    start = time.time()\n",
    "    for line in test:\n",
    "        output.write(\"  \".join(__cut(re.sub(\"\\\\s+\", \"\", line))))\n",
    "        output.write(\"\\n\")\n",
    "    runtime = time.time()-start\n",
    "print(\"P:%.2f R:%.2f F1:%.2f OOV-R:%.2f IV-R:%.2f\" % prf(msr_gold, msr_output, word_dict))\n",
    "print('runtime:{}s'.format(runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词结果输出保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(msr_gold, encoding=\"utf-8\") as test:\n",
    "    pos_list_out = []\n",
    "    cut_out = []\n",
    "    for line in test:\n",
    "        # 将每个字的标注序列输出保存，每个句子以空元素隔开\n",
    "        prob, pos_list = viterbi(re.sub(\"\\\\s+\", \"\", line), 'BMES', msr_prob_start, msr_prob_trans, msr_prob_emit)\n",
    "        for w1 in pos_list:\n",
    "            pos_list_out.append(w1)\n",
    "        pos_list_out.append(\"\")\n",
    "        # 将每个句子拆分成单字保存\n",
    "        word_split = re.sub(\"\\\\s+\",\"\",line)\n",
    "        word_split = list(''.join(word_split))\n",
    "        for w2 in word_split:\n",
    "            cut_out.append(w2)\n",
    "        cut_out.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将单字和标注序列列表合成一个数据框\n",
    "segmentation_out = pd.DataFrame({\"word\":cut_out,\"tagging\":pos_list_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>扬</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>帆</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>远</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>东</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>做</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188335</th>\n",
       "      <td>的</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188336</th>\n",
       "      <td>对</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188337</th>\n",
       "      <td>话</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188338</th>\n",
       "      <td>。</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188339</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188340 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word tagging\n",
       "0         扬       B\n",
       "1         帆       E\n",
       "2         远       B\n",
       "3         东       E\n",
       "4         做       S\n",
       "...     ...     ...\n",
       "188335    的       S\n",
       "188336    对       B\n",
       "188337    话       E\n",
       "188338    。       S\n",
       "188339             \n",
       "\n",
       "[188340 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据框保存为txt文件\n",
    "segmentation_out.to_csv(\"C:/Users/叶腱珉/Desktop/Natural Language Processing\\\n",
    "/实验四/segmentation_result.txt\",sep='\\t',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
